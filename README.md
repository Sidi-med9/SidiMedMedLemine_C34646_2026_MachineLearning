# Mini-Projet : Apprentissage SupervisÃ© LinÃ©aire
## Module : Machine Learning
## AnnÃ©e universitaire : 2026

---

## ğŸ‘¤ Informations de lâ€™Ã©tudiant
- **Nom et PrÃ©nom** : Sidi Med Med Lemine
- **Matricule** : C34646
- **Niveau** : Master 1 Intelligence Artificielle (M1 IA)
- **UniversitÃ©** : FacultÃ© des Sciences et Techniques (FST)

---

## ğŸ¯ Objectif du Mini-Projet
Lâ€™objectif de ce mini-projet est de consolider les bases de lâ€™apprentissage supervisÃ©
Ã  travers lâ€™implÃ©mentation complÃ¨te et lâ€™analyse de deux modÃ¨les fondamentaux :

- **MLS (Machine Learning SupervisÃ©)** : RÃ©gression LinÃ©aire  
- **MLNS (Classification SupervisÃ©e)** : RÃ©gression Logistique  

Le projet couvre toutes les Ã©tapes classiques dâ€™un pipeline de Machine Learning :
prÃ©paration des donnÃ©es, implÃ©mentation des algorithmes, entraÃ®nement,
Ã©valuation et interprÃ©tation des rÃ©sultats.

---

## ğŸ§© Structure du DÃ©pÃ´t
SidiMedMedLemine_C34646_2026_MachineLearning/
â”‚
â”œâ”€â”€ Mini_Projet_ML_2026_AMOUNT.ipynb
â”œâ”€â”€ README.md
â””â”€â”€ dataset/
â””â”€â”€ Insurance.csv

---

## ğŸŸ¦ PARTIE 1 : RÃ‰GRESSION LINÃ‰AIRE (MLS)

### ğŸ”¹ Dataset utilisÃ©
- **Nom du fichier** : `Insurance.csv`
- **Source** : Kaggle (dataset dâ€™assurance)
- **Variables disponibles** :
  - `Age`
  - `Policy Term`
  - `PPT`
  - `Plan` (catÃ©gorielle)
  - **`Amount`** (variable cible numÃ©rique)

### ğŸ”¹ ProblÃ¨me traitÃ©
PrÃ©dire le **montant (`Amount`)** Ã  partir des caractÃ©ristiques de lâ€™assurÃ©.

---

### ğŸ”¹ Ã‰tapes dâ€™implÃ©mentation de lâ€™algorithme

1. **Chargement des donnÃ©es**
   - Import du fichier CSV depuis Google Drive
   - VÃ©rification des colonnes et des types de donnÃ©es

2. **PrÃ©traitement**
   - Nettoyage des noms de colonnes
   - Conversion de la variable cible `Amount` en type numÃ©rique
   - Suppression des valeurs manquantes si nÃ©cessaire

3. **Encodage**
   - Transformation des variables catÃ©gorielles (ex : `Plan`)
   - Utilisation de `get_dummies()` avec suppression de la premiÃ¨re modalitÃ©

4. **Analyse exploratoire**
   - Calcul de la matrice de corrÃ©lation
   - Visualisation via une **Heatmap**

5. **Formalisation du modÃ¨le**
   - ModÃ¨le de rÃ©gression linÃ©aire :
     \[
     y = \beta_0 + \sum_{i=1}^{n} \beta_i x_i + \varepsilon
     \]

6. **SÃ©paration des donnÃ©es**
   - 80 % pour lâ€™entraÃ®nement
   - 20 % pour le test

7. **ImplÃ©mentation de lâ€™algorithme**
   - EntraÃ®nement du modÃ¨le de **RÃ©gression LinÃ©aire**

8. **PrÃ©diction**
   - PrÃ©diction des valeurs de `Amount` sur lâ€™ensemble de test

9. **Ã‰valuation**
   - Calcul de lâ€™Erreur Quadratique Moyenne (**MSE**)
   - Calcul du Coefficient de DÃ©termination (**RÂ²**)

10. **InterprÃ©tation**
    - Analyse des coefficients Î²áµ¢
    - Ã‰tude de lâ€™influence de chaque variable sur le montant prÃ©dit

---

### ğŸ”¹ Algorithme utilisÃ©
- **RÃ©gression LinÃ©aire (Machine Learning SupervisÃ© â€“ MLS)**

---

## ğŸŸ© PARTIE 2 : RÃ‰GRESSION LOGISTIQUE (MLNS)

### ğŸ”¹ Dataset utilisÃ©
- **Nom** : Iris Dataset
- **Source** : scikit-learn
- **Type de problÃ¨me** : Classification binaire (Classe 0 vs Autres)

---

### ğŸ”¹ Ã‰tapes dâ€™implÃ©mentation de lâ€™algorithme

1. **Chargement du dataset Iris**
   - Utilisation de `load_iris()` depuis scikit-learn

2. **PrÃ©paration des donnÃ©es**
   - SÃ©paration des variables dâ€™entrÃ©e (X) et de la cible (y)
   - Transformation du problÃ¨me multi-classes en **classification binaire**

3. **Normalisation**
   - Standardisation des variables avec `StandardScaler`

4. **SÃ©paration Train / Test**
   - 80 % entraÃ®nement / 20 % test

5. **ImplÃ©mentation de lâ€™algorithme**
   - EntraÃ®nement du modÃ¨le de **RÃ©gression Logistique**

6. **ModÃ©lisation probabiliste**
   - Fonction sigmoÃ¯de :
     \[
     P(y=1|x) = \frac{1}{1 + e^{-z}}
     \]

7. **Ã‰valuation**
   - Construction de la **Matrice de Confusion**
   - Calcul des mÃ©triques :
     - Accuracy
     - Precision
     - Recall

---

### ğŸ”¹ Algorithme utilisÃ©
- **RÃ©gression Logistique (Classification supervisÃ©e â€“ MLNS)**

---

## ğŸ“Š RÃ©sultats et Analyse
- La rÃ©gression linÃ©aire permet de prÃ©dire efficacement une variable continue
  et dâ€™interprÃ©ter lâ€™importance des variables explicatives.
- La rÃ©gression logistique permet de modÃ©liser une probabilitÃ© dâ€™appartenance
  Ã  une classe et dâ€™Ã©valuer les performances Ã  lâ€™aide de mÃ©triques adaptÃ©es.

---

## âœ… Conclusion
Ce mini-projet a permis dâ€™implÃ©menter pas Ã  pas deux algorithmes fondamentaux
du Machine Learning SupervisÃ©. Il a renforcÃ© la comprÃ©hension du pipeline
complet, depuis les donnÃ©es brutes jusquâ€™Ã  lâ€™interprÃ©tation des rÃ©sultats.

---

## ğŸ› ï¸ Outils utilisÃ©s
- Python
- Google Colab
- Pandas / NumPy
- Scikit-learn
- Matplotlib / Seaborn

